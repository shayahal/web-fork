---
title: "אני ו-evals נשנה את העולם"
subtitle: "או: על הקורס הכי סקסי שלמדתי בתואר: תורת המבחנים וההערכה"
date: '2025-01-20'
description: 'על evals, benchmarks, תורת המבחנים הפסיכומטרית, ומה אפשר ללמוד ממנה על הערכת LLMs'
direction: rtl
language: 'he'
tags: ['ai', 'tech', 'reflection', 'thoughts']
---

evals ו-benchmarks הם בעצם אחד החלקים הכי משמעותיים בפיתוח המודלים של ימינו. 

בהפשטה גסה, ה-LLM-ים שאנחנו מכירים הם בעצם רשת נוירונים שיודעת ללמוד בצורה מאוד יעילה, בתוספת *המון המון מבחנים* שבודקים את היכולות שלהם - מטלות שפה, מתמטיקה, סיכום... ברצף ארוך של פעולות אלגבריות ודאטה רלוונטי, מזיזים את המודל להיות יותר ויותר טוב בהם. המבחנים האלו נקראים evals - חלק מהמתכון הסודי של המודל. 

כדי להשוות בין מודלים, הקהילה המדעית בנתה benchmarks - מבחנים סטנדרטיים ופומביים שבאמצעותם מדגימים את ההתקדמות של המודלים ביכולות שונות (כמו לפתור באגים ב-repo בגיטהאב) או בסוגיות של safety (נגיד, האם המודלים מסרבים לבקשות שהן harmful כמו לפרוץ לאתר). 

עד כאן נשמע מגניב. איפה זה מתחיל להיות מורכב? כשמתחילים להסתכל לעומק, רואים שהביצועים של המודלים לפעמים יורדים דרמטית אם עושים וריאציות קטנות במבחן: משנים את סדר התשובות במבחן אמריקאי, בוחנים על שאלות מתמטיות אחרות באותה רמת קושי או מורידים חלקים מהרקע בתמונה. 

כלומר, ה-benchmarks לא תמיד באמת טובים בלנבא עד כמה המודל יהיה אשכרה טוב בעולם האמיתי. זה יכול לקרות אם מודלים נחשפים בתהליך האימון לדאטה הזה (contamination) או כי המודלים משננים ולומדים להיות ממש טובים במבחן הזה באופן ספציפי (שווה לקרוא על חוק גודהארט) ולא באמת עושים ג'נרליזציה, או פשוט כי הם לא מודדים את מה שהם היו אמורים למדוד.  

הקהילה המדעית כבר מודעת לכמה הבעיה כואבת, והקריאה לבנות מדע חדש של evals הולכת ונהיית דחופה יותר. 

אבל רגע, אנחנו בעצם מתעסקים במבחנים כבר הרבה שנים! ב-1904 צ׳ארלס ספירמן שם לב שכשאנשים נבחנים בכמה משימות קוגניטיביות (מילוליות, מתמטיות, חזותיות) יש קורלציה גבוהה בתוצאות. הוא פיתח תיאוריה שאומרת שיש בעצם גורם אחד יחיד שמשותף לכל המשימות הקוגניטיביות, שאותו אנחנו מודדים בכל המבחנים! הוא קרא לו g - מלשון general intelligence (מזכיר משהו?). 

הסתבר שאותו ה-g הוא אחד המנבאים הפסיכומטריים החזקים ביותר לאינסוף דברים טובים: הצלחה בעבודה ובאקדמיה, מצב סוציו אקונומי, יציבות נישואין, בריאות, תוחלת חיים… לא מפתיע שכבר יותר ממאה שנים חוקרים עובדים קשה כדי לבנות מבחנים עבורו. 

מבחן הזהב ל-IQ הוא מבחן וקסלר לאינטליגנציה. הוא לא האמין בציון g אחד, אלא בנה מבחן מסוג אחר: יושבים 1:1 עם פסיכולוג.ית מוסמכים שמעבירים סדרה של תתי מבחנים מילוליים ומעשיים. אחרי 3 טעויות בתת הנושא עוברים לנושא הבא - לכן ככל שתהיי טובה יותר המבחן יתארך. 

Fun fact: מטרת הפסיכומטרי הוא להתקרב לציון של מבחן וקסלר, עם דגש על תתי המבחנים שמנבאים ביצועים אקדמיים. ולמרות שאנחנו אוהבים לשנוא אותו, הוא בעצם מבחן ממש מוצלח: הקורלציה בין הציון בו לבין ההצלחה של סטודנטים בשנה הראשונה ממש גבוהה - בדיוק את מה שהוא אמור לעשות. 

אז מה אפשר ללמוד מהתיאוריה של תורת המבחנים לאיך אנחנו מתייחסים לבנצ׳מרקים של LLMs? 

כשיש שני בנצ'מרקים עם קורלציה גבוהה מאוד - ייתכן שהם מודדים את אותה התכונה הבסיסית (אולי ה-g!) בנצ׳מרקים צריכים לשאוף למדוד יכולות ספציפיות ובלתי תלויות. 

הרבה מהם עברו saturation - כל המודלים הגדולים כבר מצוינים בהם, וכשכולם מקבלים 95% אי אפשר באמת להבדיל. מבחן אדפטיבי - שבו ככל שאתה טוב יותר תקבל שאלות קשות יותר - יכול לפתור את הבעיה.

מבחני אינטליגנציה כוללים גם חלקים מעשיים - הרבה יותר מעניין לבדוק את ההצלחה של המודל במשימה שלמה ולא חלק ממנה הוא הדבר החשוב ביותר. 

וכל החפירה הזו הייתה כדי לספר שבשבוע שעבר יצא המבחן האהוב עליי, vending-bench-2: 

https://andonlabs.com/evals/vending-bench-2

